# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹ - Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ ÙÙˆØ±ÛŒ

## ğŸš€ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø´Ø§Ù…Ù„ Ú©Ø¯Ù‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ ÙÙˆØ±ÛŒ Ø§Ø³Øª.

---

## 1. ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ OpenAI Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§

### 1.1 Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: `backend/core/content_generation/ai_generator.py`

```python
"""
ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ OpenAI GPT-4
"""

import os
import logging
from typing import Dict, Any, List
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class AIContentGenerator:
    """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² OpenAI"""
    
    def __init__(self):
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = os.getenv('AI_CONTENT_MODEL', 'gpt-4-turbo-preview')
    
    async def generate_article(
        self,
        keyword: str,
        keyword_metrics: Dict[str, Any] = None,
        competitor_content: List[Dict] = None,
        target_length: int = 1500,
        language: str = 'fa'
    ) -> Dict[str, Any]:
        """
        ØªÙˆÙ„ÛŒØ¯ Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ø§ AI
        
        Args:
            keyword: Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ
            keyword_metrics: Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ (search volume, difficulty, etc.)
            competitor_content: Ù…Ø­ØªÙˆØ§ÛŒ Ø±Ù‚Ø¨Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            target_length: Ø·ÙˆÙ„ Ù‡Ø¯Ù Ù…Ù‚Ø§Ù„Ù‡ (ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª)
            language: Ø²Ø¨Ø§Ù† Ù…Ø­ØªÙˆØ§ ('fa' ÛŒØ§ 'en')
        
        Returns:
            Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ SEO
        """
        try:
            # Ø³Ø§Ø®Øª prompt Ù¾ÛŒØ´Ø±ÙØªÙ‡
            prompt = self._build_prompt(
                keyword=keyword,
                keyword_metrics=keyword_metrics or {},
                competitor_content=competitor_content or [],
                target_length=target_length,
                language=language
            )
            
            # ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø¨Ø§ OpenAI
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt(language)
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=target_length * 2,  # ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª
                top_p=0.9,
                frequency_penalty=0.3,
                presence_penalty=0.3
            )
            
            content = response.choices[0].message.content
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ SEO
            seo_metrics = self._calculate_seo_metrics(content, keyword, language)
            
            return {
                'content': content,
                'title': self._extract_title(content),
                'meta_description': self._generate_meta_description(content, keyword, language),
                'word_count': len(content.split()),
                'seo_score': seo_metrics['seo_score'],
                'keyword_density': seo_metrics['keyword_density'],
                'readability_score': seo_metrics['readability'],
                'headings': self._extract_headings(content),
                'language': language,
                'generated_by': 'openai_gpt4'
            }
            
        except Exception as e:
            logger.error(f"Error generating content with AI: {str(e)}")
            raise
    
    def _get_system_prompt(self, language: str) -> str:
        """Ù¾ÛŒØ§Ù… Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø§ÛŒ AI"""
        if language == 'fa':
            return """Ø´Ù…Ø§ ÛŒÚ© Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù…ØªØ®ØµØµ SEO Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ù‡Ø³ØªÛŒØ¯. 
            Ù…Ø­ØªÙˆØ§ÛŒ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯:
            - Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…ÙˆØªÙˆØ±Ù‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§Ø´Ø¯
            - Ø§Ø±Ø²Ø´Ù…Ù†Ø¯ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
            - Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø¸Ù… Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            - Ø§Ø² Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯
            - Ø®ÙˆØ§Ù†Ø§ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ø§Ø´Ø¯"""
        else:
            return """You are an expert SEO content writer.
            Your content must be:
            - SEO optimized
            - Valuable and useful for readers
            - Well-structured with appropriate headings
            - Use keywords naturally
            - Readable and engaging"""
    
    def _build_prompt(
        self,
        keyword: str,
        keyword_metrics: Dict[str, Any],
        competitor_content: List[Dict],
        target_length: int,
        language: str
    ) -> str:
        """Ø³Ø§Ø®Øª prompt Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        
        # Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§
        competitor_summary = ""
        if competitor_content:
            competitor_summary = self._summarize_competitors(competitor_content, language)
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
        metrics_text = ""
        if keyword_metrics:
            metrics_text = f"""
            Keyword Metrics:
            - Search Volume: {keyword_metrics.get('search_volume', 'N/A')}
            - Difficulty: {keyword_metrics.get('difficulty', 'N/A')}
            - Competition: {keyword_metrics.get('competition', 'N/A')}
            """
        
        if language == 'fa':
            prompt = f"""
            ÛŒÚ© Ù…Ù‚Ø§Ù„Ù‡ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ SEO Ø¯Ø±Ø¨Ø§Ø±Ù‡ "{keyword}" Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.
            
            {metrics_text}
            
            {competitor_summary}
            
            Ø§Ù„Ø²Ø§Ù…Ø§Øª:
            - Ø·ÙˆÙ„ Ù…Ù‚Ø§Ù„Ù‡: Ø­Ø¯ÙˆØ¯ {target_length} Ú©Ù„Ù…Ù‡
            - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø² Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ "{keyword}" (Ú†Ú¯Ø§Ù„ÛŒ 1-2%)
            - Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø¸Ù… Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ÛŒ H2 Ùˆ H3
            - Ù…Ù‚Ø¯Ù…Ù‡ Ø¬Ø°Ø§Ø¨ Ø¯Ø± 100 Ú©Ù„Ù…Ù‡ Ø§ÙˆÙ„
            - Ù…Ø­ØªÙˆØ§ÛŒ Ø§Ø±Ø²Ø´Ù…Ù†Ø¯ Ùˆ Ø¹Ù…ÛŒÙ‚
            - Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù† Ø¨Ù‡ Ø¹Ù…Ù„
            - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù…Ø±ØªØ¨Ø·
            
            Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:
            """
        else:
            prompt = f"""
            Write a comprehensive, SEO-optimized article about "{keyword}".
            
            {metrics_text}
            
            {competitor_summary}
            
            Requirements:
            - Article length: approximately {target_length} words
            - Natural use of keyword "{keyword}" (density 1-2%)
            - Well-structured with H2 and H3 headings
            - Engaging introduction in first 100 words
            - Valuable and in-depth content
            - Conclusion with call-to-action
            - Use related semantic keywords
            
            Write the article now:
            """
        
        return prompt
    
    def _summarize_competitors(self, competitor_content: List[Dict], language: str) -> str:
        """Ø®Ù„Ø§ØµÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ Ø±Ù‚Ø¨Ø§"""
        if not competitor_content:
            return ""
        
        summary_parts = []
        if language == 'fa':
            summary_parts.append("ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ø±Ù‚Ø¨Ø§:")
            summary_parts.append(f"- ØªØ¹Ø¯Ø§Ø¯ Ø±Ù‚Ø¨Ø§: {len(competitor_content)}")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…Ø´ØªØ±Ú©
            common_topics = set()
            for content in competitor_content[:3]:  # 3 Ø±Ù‚ÛŒØ¨ Ø§ÙˆÙ„
                if 'topics' in content:
                    common_topics.update(content['topics'])
            
            if common_topics:
                summary_parts.append(f"- Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…Ø´ØªØ±Ú©: {', '.join(list(common_topics)[:5])}")
        else:
            summary_parts.append("Competitor Content Analysis:")
            summary_parts.append(f"- Number of competitors: {len(competitor_content)}")
        
        return "\n".join(summary_parts)
    
    def _calculate_seo_metrics(
        self,
        content: str,
        keyword: str,
        language: str
    ) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ SEO"""
        words = content.lower().split()
        keyword_lower = keyword.lower()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Keyword Density
        keyword_count = sum(1 for word in words if keyword_lower in word.lower())
        total_words = len(words)
        keyword_density = (keyword_count / total_words * 100) if total_words > 0 else 0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ SEO Score (Ø³Ø§Ø¯Ù‡)
        seo_score = 0
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± 100 Ú©Ù„Ù…Ù‡ Ø§ÙˆÙ„
        if keyword_lower in ' '.join(words[:100]).lower():
            seo_score += 20
        
        # Ø¨Ø±Ø±Ø³ÛŒ Keyword Density
        if 1 <= keyword_density <= 2:
            seo_score += 20
        elif 0.5 <= keyword_density < 1 or 2 < keyword_density <= 3:
            seo_score += 10
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§
        if 1000 <= total_words <= 3000:
            seo_score += 20
        elif 500 <= total_words < 1000 or 3000 < total_words <= 5000:
            seo_score += 10
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§
        if '##' in content or '<h2>' in content.lower():
            seo_score += 20
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ (Ø³Ø§Ø¯Ù‡)
        avg_sentence_length = total_words / max(content.count('.'), 1)
        if 15 <= avg_sentence_length <= 25:
            seo_score += 20
        
        return {
            'seo_score': min(seo_score, 100),
            'keyword_density': round(keyword_density, 2),
            'readability': self._simple_readability_score(content, language)
        }
    
    def _simple_readability_score(self, content: str, language: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ø¯Ù‡ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ"""
        sentences = content.split('.')
        words = content.split()
        
        if not sentences or not words:
            return 0
        
        avg_sentence_length = len(words) / len(sentences)
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø³Ø§Ø¯Ù‡ (Ù‡Ø±Ú†Ù‡ Ø¬Ù…Ù„Ø§Øª Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ØŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±)
        if avg_sentence_length <= 15:
            return 90
        elif avg_sentence_length <= 20:
            return 75
        elif avg_sentence_length <= 25:
            return 60
        else:
            return 45
    
    def _extract_title(self, content: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø§Ø² Ù…Ø­ØªÙˆØ§"""
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                return line[2:].strip()
            elif line and len(line) < 100:
                return line
        return "Ù…Ù‚Ø§Ù„Ù‡ SEO"
    
    def _generate_meta_description(
        self,
        content: str,
        keyword: str,
        language: str
    ) -> str:
        """ØªÙˆÙ„ÛŒØ¯ meta description"""
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 2-3 Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„
        sentences = content.split('.')[:3]
        description = '. '.join(sentences).strip()
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ 160 Ú©Ø§Ø±Ø§Ú©ØªØ±
        if len(description) > 160:
            description = description[:157] + '...'
        
        return description
    
    def _extract_headings(self, content: str) -> List[Dict[str, str]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ Ø§Ø² Ù…Ø­ØªÙˆØ§"""
        headings = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('## '):
                headings.append({
                    'level': 'h2',
                    'text': line[3:].strip()
                })
            elif line.startswith('### '):
                headings.append({
                    'level': 'h3',
                    'text': line[4:].strip()
                })
        
        return headings
```

---

## 2. ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ SEMrush API

### 2.1 Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„: `backend/core/keyword_research/semrush_client.py`

```python
"""
ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ SEMrush API Ø¨Ø±Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
"""

import os
import logging
import httpx
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)


class SEMrushKeywordAnalyzer:
    """ØªØ­Ù„ÛŒÙ„ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ SEMrush"""
    
    def __init__(self):
        self.api_key = os.getenv('SEMRUSH_API_KEY')
        if not self.api_key:
            logger.warning("SEMRUSH_API_KEY not found. SEMrush features will be disabled.")
            self.enabled = False
        else:
            self.enabled = True
            self.base_url = "https://api.semrush.com/"
    
    async def get_keyword_overview(
        self,
        keyword: str,
        database: str = 'us'  # us, uk, ca, au, etc.
    ) -> Optional[Dict[str, Any]]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø§Ù…Ø¹ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
        
        Returns:
            {
                'keyword': str,
                'search_volume': int,
                'cpc': float,
                'competition': float,
                'competition_level': str,  # Low, Medium, High
                'trend': List[int],  # 12 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡
                'difficulty': int  # 0-100
            }
        """
        if not self.enabled:
            return None
        
        try:
            params = {
                'key': self.api_key,
                'type': 'phrase_this',
                'phrase': keyword,
                'database': database,
                'export_columns': 'Ph,Nq,Cp,Co,Nr,Td'
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.base_url}",
                    params=params,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    return self._parse_keyword_overview(response.text, keyword)
                else:
                    logger.error(f"SEMrush API error: {response.status_code}")
                    return None
                    
        except Exception as e:
            logger.error(f"Error fetching keyword overview from SEMrush: {str(e)}")
            return None
    
    def _parse_keyword_overview(self, response_text: str, keyword: str) -> Dict[str, Any]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® SEMrush"""
        lines = response_text.strip().split('\n')
        if not lines or len(lines) < 2:
            return None
        
        # ÙØ±Ù…Øª: Phrase;Search Volume;CPC;Competition;Number of Results;Trend
        data = lines[1].split(';')
        
        if len(data) < 6:
            return None
        
        try:
            search_volume = int(data[1]) if data[1] else 0
            cpc = float(data[2]) if data[2] else 0.0
            competition = float(data[3]) if data[3] else 0.0
            
            # ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­ Ø±Ù‚Ø§Ø¨Øª
            if competition < 0.3:
                competition_level = 'Low'
            elif competition < 0.7:
                competition_level = 'Medium'
            else:
                competition_level = 'High'
            
            # Trend (12 Ù…Ø§Ù‡)
            trend_data = data[5].split(',') if len(data) > 5 else []
            trend = [int(x) for x in trend_data[:12]] if trend_data else []
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Keyword Difficulty (Ø³Ø§Ø¯Ù‡)
            difficulty = self._calculate_difficulty(competition, search_volume)
            
            return {
                'keyword': keyword,
                'search_volume': search_volume,
                'cpc': cpc,
                'competition': competition,
                'competition_level': competition_level,
                'trend': trend,
                'difficulty': difficulty,
                'number_of_results': int(data[4]) if len(data) > 4 and data[4] else 0
            }
        except Exception as e:
            logger.error(f"Error parsing SEMrush response: {str(e)}")
            return None
    
    def _calculate_difficulty(self, competition: float, search_volume: int) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Keyword Difficulty (0-100)"""
        # ÙØ±Ù…ÙˆÙ„ Ø³Ø§Ø¯Ù‡: ØªØ±Ú©ÛŒØ¨ Competition Ùˆ Search Volume
        base_score = int(competition * 50)  # 0-50 Ø§Ø² competition
        
        # ØªØ¹Ø¯ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Search Volume
        if search_volume > 10000:
            volume_score = 30
        elif search_volume > 1000:
            volume_score = 20
        elif search_volume > 100:
            volume_score = 10
        else:
            volume_score = 5
        
        difficulty = min(base_score + volume_score, 100)
        return difficulty
    
    async def get_related_keywords(
        self,
        keyword: str,
        database: str = 'us',
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·"""
        if not self.enabled:
            return []
        
        try:
            params = {
                'key': self.api_key,
                'type': 'phrase_related',
                'phrase': keyword,
                'database': database,
                'export_columns': 'Ph,Nq,Cp,Co'
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.base_url}",
                    params=params,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    return self._parse_related_keywords(response.text, limit)
                else:
                    return []
                    
        except Exception as e:
            logger.error(f"Error fetching related keywords: {str(e)}")
            return []
    
    def _parse_related_keywords(self, response_text: str, limit: int) -> List[Dict[str, Any]]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·"""
        keywords = []
        lines = response_text.strip().split('\n')
        
        for line in lines[1:limit+1]:  # Ø®Ø· Ø§ÙˆÙ„ header Ø§Ø³Øª
            data = line.split(';')
            if len(data) >= 4:
                try:
                    keywords.append({
                        'keyword': data[0],
                        'search_volume': int(data[1]) if data[1] else 0,
                        'cpc': float(data[2]) if data[2] else 0.0,
                        'competition': float(data[3]) if data[3] else 0.0
                    })
                except:
                    continue
        
        return keywords
```

---

## 3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ContentGenerator Ù…ÙˆØ¬ÙˆØ¯

### 3.1 Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AI Generator

Ø¯Ø± ÙØ§ÛŒÙ„ `backend/core/content_generator.py`:

```python
# Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ ÙØ§ÛŒÙ„
from .content_generation.ai_generator import AIContentGenerator

class ContentGenerator:
    def __init__(self):
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† AI Generator
        try:
            self.ai_generator = AIContentGenerator()
            self.ai_enabled = True
        except Exception as e:
            logger.warning(f"AI Generator not available: {str(e)}")
            self.ai_generator = None
            self.ai_enabled = False
    
    async def _generate_text_content_for_keyword(
        self,
        keyword: str,
        site_url: str,
        language: str = 'fa'
    ) -> List[Dict[str, Any]]:
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø®Ø§Øµ"""
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AI Generator Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        if self.ai_enabled and self.ai_generator:
            try:
                # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ (Ø§Ú¯Ø± SEMrush Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
                keyword_metrics = await self._get_keyword_metrics(keyword)
                
                # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø§ AI
                ai_content = await self.ai_generator.generate_article(
                    keyword=keyword,
                    keyword_metrics=keyword_metrics,
                    target_length=1500,
                    language=language
                )
                
                return [{
                    'id': f"content_{hash(keyword)}_{datetime.now().timestamp()}",
                    'title': ai_content['title'],
                    'content': ai_content['content'],
                    'type': 'article',
                    'word_count': ai_content['word_count'],
                    'keywords': [keyword],
                    'status': 'generated',
                    'created_at': datetime.now().isoformat(),
                    'seo_score': ai_content['seo_score'],
                    'description': ai_content['meta_description'],
                    'headings': ai_content['headings'],
                    'generated_by': 'ai'
                }]
            except Exception as e:
                logger.error(f"Error generating with AI, falling back to template: {str(e)}")
        
        # Fallback Ø¨Ù‡ Ø±ÙˆØ´ Ù‚Ø¨Ù„ÛŒ (template-based)
        return await self._generate_template_content(keyword, site_url, language)
    
    async def _get_keyword_metrics(self, keyword: str) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ"""
        try:
            from .keyword_research.semrush_client import SEMrushKeywordAnalyzer
            semrush = SEMrushKeywordAnalyzer()
            if semrush.enabled:
                return await semrush.get_keyword_overview(keyword)
        except:
            pass
        return {}
```

---

## 4. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ requirements.txt

```txt
# AI Content Generation
openai==1.3.5  # Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª

# Keyword Research
httpx==0.25.1  # Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª
```

---

## 5. ØªÙ†Ø¸ÛŒÙ… Environment Variables

Ø¯Ø± ÙØ§ÛŒÙ„ `.env`:

```env
# OpenAI API
OPENAI_API_KEY=sk-your-openai-api-key-here

# SEMrush API (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
SEMRUSH_API_KEY=your-semrush-api-key-here

# Configuration
AI_CONTENT_MODEL=gpt-4-turbo-preview
```

---

## 6. ØªØ³Øª Ø³Ø±ÛŒØ¹

### ØªØ³Øª AI Content Generator:

```python
import asyncio
from backend.core.content_generation.ai_generator import AIContentGenerator

async def test_ai_generator():
    generator = AIContentGenerator()
    
    result = await generator.generate_article(
        keyword="Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ",
        target_length=1000,
        language='fa'
    )
    
    print(f"Title: {result['title']}")
    print(f"Word Count: {result['word_count']}")
    print(f"SEO Score: {result['seo_score']}")
    print(f"Content Preview: {result['content'][:200]}...")

# Ø§Ø¬Ø±Ø§
asyncio.run(test_ai_generator())
```

---

## ğŸ“ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

1. **API Keys**: Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ API keys Ø±Ø§ Ø¯Ø± `.env` ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯
2. **Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§**: OpenAI GPT-4 Ù‡Ø²ÛŒÙ†Ù‡â€ŒØ¨Ø± Ø§Ø³ØªØŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø§Ø² GPT-3.5-turbo Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
3. **Rate Limits**: Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ API ØªÙˆØ¬Ù‡ Ú©Ù†ÛŒØ¯
4. **Error Handling**: Ù‡Ù…ÛŒØ´Ù‡ fallback Ø¨Ù‡ Ø±ÙˆØ´ Ù‚Ø¨Ù„ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯

---

**Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ!** ğŸš€

