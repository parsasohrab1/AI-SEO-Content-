# ุฑุงูููุง Local AI Content Generator

## ๐ ูุนุฑู

ุงู ูุงฺูู ุชููุฏ ูุญุชูุง ุจุง ุงุณุชูุงุฏู ุงุฒ ูุฏูโูุง Open Source (Llama 2, Mistral ู ุบุฑู) ุฑุง ุงูุฌุงู ูโุฏูุฏ. ุงู ฺฉ ุฌุงฺฏุฒู ุฑุงฺฏุงู ุจุฑุง OpenAI API ุงุณุช ฺฉู ูโุชูุงูุฏ ุจู ุตูุฑุช ูุญู ุงุฌุฑุง ุดูุฏ.

## โจ ูฺฺฏโูุง

- โ ุงุณุชูุงุฏู ุงุฒ ูุฏูโูุง Open Source (Mistral, Llama 2, GPT-2)
- โ ุงุฌุฑุง ูุญู (ุจุฏูู ูุงุฒ ุจู API)
- โ ฺฉุงูุด ูุฒูู (ุฑุงฺฏุงู)
- โ ูพุดุชุจุงู ุงุฒ CPU ู GPU
- โ ูพุดุชุจุงู ุงุฒ 8-bit ู 4-bit quantization
- โ ุชููุฏ ูุญุชูุง ุจููู ุจุฑุง SEO
- โ ูพุดุชุจุงู ุงุฒ ูุงุฑุณ ู ุงูฺฏูุณ

## ๐ ูุตุจ

### ูุงุจุณุชฺฏโูุง ููุฑุฏ ูุงุฒ

```bash
# ูพุงู
pip install transformers torch

# ุจุฑุง GPU (ุงุฎุชุงุฑ)
pip install torch --index-url https://download.pytorch.org/whl/cu118

# ุจุฑุง quantization (ุงุฎุชุงุฑ)
pip install bitsandbytes accelerate
```

### ุชูุธูุงุช

```bash
# ุฏุฑ ูุงู .env
LOCAL_AI_MODEL=mistralai/Mistral-7B-Instruct-v0.2  # ุง llama2, gpt2
LOCAL_AI_DEVICE=auto  # auto, cpu, cuda
LOCAL_AI_8BIT=false  # ุงุณุชูุงุฏู ุงุฒ 8-bit quantization
LOCAL_AI_4BIT=false  # ุงุณุชูุงุฏู ุงุฒ 4-bit quantization
```

## ๐ ุงุณุชูุงุฏู

### ูุซุงู 1: ุชููุฏ ุณุงุฏู

```python
from backend.core.content_generator import LocalAIContentGenerator

generator = LocalAIContentGenerator()

result = await generator.generate_article(
    keyword="seo optimization",
    target_length=1500,
    language='en'
)

print(f"Title: {result['title']}")
print(f"Content: {result['content']}")
print(f"SEO Score: {result['seo_score']}/100")
```

### ูุซุงู 2: ุงุณุชูุงุฏู ุงุฒ ูุฏู ุฎุงุต

```python
# ุงุณุชูุงุฏู ุงุฒ ูุฏู ฺฉูฺฺฉโุชุฑ ุจุฑุง ุชุณุช
generator = LocalAIContentGenerator(model_name="gpt2")

result = await generator.generate_article(
    keyword="seo",
    target_length=1000,
    language='en'
)
```

### ูุซุงู 3: ุงุณุชูุงุฏู ุจุง GPU

```python
# ุชูุธู device ุจู cuda
generator = LocalAIContentGenerator()
# ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ GPU ุฑุง ุชุดุฎุต ูโุฏูุฏ
```

## ๐ ุณุงุฎุชุงุฑ ุฏุงุฏูโูุง ุจุงุฒฺฏุดุช

```python
{
    'content': str,
    'title': str,
    'meta_description': str,
    'seo_score': float,
    'keyword_density': float,
    'readability': float,
    'word_count': int,
    'headings': List[str],
    'faq': List[Dict],
    'recommendations': List[str],
    'keyword': str,
    'language': str,
    'model': str  # ูุงู ูุฏู ุงุณุชูุงุฏู ุดุฏู
}
```

## ๐ฏ ูุฏูโูุง ูพุดุชุจุงู ุดุฏู

### 1. Mistral
- `mistralai/Mistral-7B-Instruct-v0.2` (ูพุดโูุฑุถ)
- ฺฉูุช ุจุงูุง
- ูุงุฒ ุจู RAM: ~14 GB

### 2. Llama 2
- `meta-llama/Llama-2-7b-chat-hf`
- ฺฉูุช ุจุงูุง
- ูุงุฒ ุจู RAM: ~14 GB

### 3. GPT-2
- `gpt2` (ุจุฑุง ุชุณุช)
- ฺฉูุช ูุชูุณุท
- ูุงุฒ ุจู RAM: ~2 GB

### 4. ุณุงุฑ ูุฏูโูุง
- ูุฑ ูุฏู Hugging Face ฺฉู ุงุฒ `text-generation` pipeline ูพุดุชุจุงู ฺฉูุฏ

## ๐ง ุชูุธูุงุช ูพุดุฑูุชู

### ุงุณุชูุงุฏู ุงุฒ Quantization

```bash
# 8-bit quantization (ฺฉุงูุด ุงุณุชูุงุฏู ุงุฒ RAM)
LOCAL_AI_8BIT=true

# 4-bit quantization (ฺฉุงูุด ุจุดุชุฑ)
LOCAL_AI_4BIT=true
```

### ุงูุชุฎุงุจ Device

```python
# CPU
generator = LocalAIContentGenerator()
# device ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ CPU ุงูุชุฎุงุจ ูโุดูุฏ

# GPU (ุงฺฏุฑ ููุฌูุฏ ุจุงุดุฏ)
# ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ GPU ุฑุง ุชุดุฎุต ูโุฏูุฏ
```

## ๐ ูุซุงู ฺฉุงูู

```python
import asyncio
from backend.core.content_generator import LocalAIContentGenerator

async def main():
    generator = LocalAIContentGenerator()
    
    if not generator.enabled:
        print("โ๏ธ Model not loaded")
        return
    
    result = await generator.generate_article(
        keyword="seo optimization",
        keyword_metrics={
            'search_volume': 12000,
            'difficulty': 65
        },
        target_length=2000,
        language='en'
    )
    
    print(f"Title: {result['title']}")
    print(f"SEO Score: {result['seo_score']}/100")
    print(f"Word Count: {result['word_count']}")

asyncio.run(main())
```

## โ๏ธ ูุญุฏูุฏุชโูุง

### RAM
- ูุฏูโูุง ุจุฒุฑฺฏ ูุงุฒ ุจู RAM ุฒุงุฏ ุฏุงุฑูุฏ
- Mistral/Llama 2: ~14 GB RAM
- GPT-2: ~2 GB RAM
- ุงุณุชูุงุฏู ุงุฒ quantization ุจุฑุง ฺฉุงูุด RAM

### ุณุฑุนุช
- CPU: ฺฉูุฏุชุฑ ุงุฒ GPU
- GPU: ุณุฑุนโุชุฑ ุงูุง ูุงุฒ ุจู GPU ููุงุณุจ
- ุงููู ุจุงุฑ: ุฏุงูููุฏ ูุฏู ุฒูุงูโุจุฑ ุงุณุช

### ฺฉูุช
- ฺฉูุช ููฺฉู ุงุณุช ฺฉูุชุฑ ุงุฒ GPT-4 ุจุงุดุฏ
- ุจุณุชฺฏ ุจู ูุฏู ุงูุชุฎุงุจ ุดุฏู ุฏุงุฑุฏ
- ูุงุฒ ุจู ูุฑุงุด ู ุจูุจูุฏ

## ๐ก ุจูุชุฑู ุฑูุดโูุง

1. **ุดุฑูุน ุจุง GPT-2**: ุจุฑุง ุชุณุช ุงุฒ GPT-2 ุงุณุชูุงุฏู ฺฉูุฏ
2. **ุงุณุชูุงุฏู ุงุฒ GPU**: ุจุฑุง ุณุฑุนุช ุจุดุชุฑ ุงุฒ GPU ุงุณุชูุงุฏู ฺฉูุฏ
3. **Quantization**: ุจุฑุง ฺฉุงูุด RAM ุงุฒ quantization ุงุณุชูุงุฏู ฺฉูุฏ
4. **ูุฑุงุด**: ููุดู ูุญุชูุง ุฑุง ูุฑุงุด ฺฉูุฏ

## ๐ ููุงุณู ุจุง OpenAI

| ูฺฺฏ | OpenAI GPT-4 | Local AI |
|-------|--------------|----------|
| ูุฒูู | ูพูู | ุฑุงฺฏุงู |
| ฺฉูุช | ุจุงูุง | ูุชูุณุท-ุจุงูุง |
| ุณุฑุนุช | ุณุฑุน | ฺฉูุฏุชุฑ |
| ูุงุฒ ุจู RAM | ูุฏุงุฑุฏ | ุฏุงุฑุฏ |
| ูุงุฒ ุจู GPU | ูุฏุงุฑุฏ | ุงุฎุชุงุฑ |
| Privacy | API | ูุญู |

## ๐ ููุงุจุน

- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [Mistral Models](https://huggingface.co/mistralai)
- [Llama 2](https://huggingface.co/meta-llama)
- [Quantization Guide](https://huggingface.co/docs/transformers/quantization)

---

**ููุณูุฏู:** AI-SEO-Content Team  
**ุชุงุฑุฎ:** 2024

