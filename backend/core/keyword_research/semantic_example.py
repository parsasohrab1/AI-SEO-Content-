"""
Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Semantic Keyword Analyzer
"""

import asyncio
import logging
from .semantic_analyzer import SemanticKeywordAnalyzer

# ØªÙ†Ø¸ÛŒÙ… logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def example_find_semantic_keywords():
    """Ù…Ø«Ø§Ù„: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        print("Installing: pip install sentence-transformers")
        print("Model will be downloaded on first use.")
        return
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ
    semantic_keywords = await analyzer.find_semantic_keywords(
        main_keyword="seo optimization",
        threshold=0.6,
        top_n=20,
        language='en'
    )
    
    if semantic_keywords:
        print(f"\nâœ… {len(semantic_keywords)} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯:\n")
        
        # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡
        by_relation = {}
        for kw in semantic_keywords:
            relation = kw.get('semantic_relation', 'unknown')
            if relation not in by_relation:
                by_relation[relation] = []
            by_relation[relation].append(kw)
        
        for relation, kws in by_relation.items():
            print(f"\nğŸ“Š {relation} ({len(kws)} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ):")
            for kw in kws[:5]:
                print(f"  â€¢ {kw['keyword']} (similarity: {kw['similarity']:.2f})")
    else:
        print("âŒ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")


async def example_lsi_keywords():
    """Ù…Ø«Ø§Ù„: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ LSI"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        return
    
    main_keyword = "seo"
    context_keywords = [
        "search engine optimization",
        "keyword research",
        "on-page seo",
        "off-page seo",
        "link building",
        "content marketing",
        "technical seo"
    ]
    
    lsi_keywords = await analyzer.find_lsi_keywords(
        main_keyword=main_keyword,
        context_keywords=context_keywords,
        top_n=10
    )
    
    if lsi_keywords:
        print(f"\nâœ… {len(lsi_keywords)} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ LSI Ù¾ÛŒØ¯Ø§ Ø´Ø¯:\n")
        for kw in lsi_keywords:
            print(f"  â€¢ {kw['keyword']}")
            print(f"    LSI Score: {kw['lsi_score']:.2f}")
    else:
        print("âŒ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ LSI Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")


async def example_cluster_keywords():
    """Ù…Ø«Ø§Ù„: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        return
    
    keywords = [
        "seo optimization",
        "keyword research",
        "link building",
        "content marketing",
        "social media marketing",
        "email marketing",
        "ppc advertising",
        "google ads",
        "facebook ads",
        "on-page seo",
        "off-page seo",
        "technical seo"
    ]
    
    clusters = await analyzer.cluster_semantic_keywords(
        keywords=keywords,
        n_clusters=3
    )
    
    if clusters:
        print(f"\nâœ… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± {len(clusters)} Ø®ÙˆØ´Ù‡:\n")
        for cluster_id, cluster_keywords in clusters.items():
            print(f"\nğŸ“¦ Ø®ÙˆØ´Ù‡ {cluster_id + 1}:")
            for kw in cluster_keywords:
                print(f"  â€¢ {kw}")
    else:
        print("âŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯")


async def example_expand_keyword():
    """Ù…Ø«Ø§Ù„: Ú¯Ø³ØªØ±Ø´ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        return
    
    keyword = "seo"
    
    # Ú¯Ø³ØªØ±Ø´ Ø¨Ù‡ ØµÙˆØ±Øª synonyms
    synonyms = await analyzer.expand_keyword_semantically(
        keyword=keyword,
        expansion_type='synonyms',
        language='en'
    )
    
    print(f"\nâœ… Synonyms Ø¨Ø±Ø§ÛŒ '{keyword}':")
    for syn in synonyms[:10]:
        print(f"  â€¢ {syn}")
    
    # Ú¯Ø³ØªØ±Ø´ Ø¨Ù‡ ØµÙˆØ±Øª related
    related = await analyzer.expand_keyword_semantically(
        keyword=keyword,
        expansion_type='related',
        language='en'
    )
    
    print(f"\nâœ… Related keywords Ø¨Ø±Ø§ÛŒ '{keyword}':")
    for rel in related[:10]:
        print(f"  â€¢ {rel}")


async def example_semantic_relationship():
    """Ù…Ø«Ø§Ù„: Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        return
    
    keyword_pairs = [
        ("seo", "search engine optimization"),
        ("seo", "content marketing"),
        ("keyword research", "keyword analysis"),
        ("seo", "cooking recipe")
    ]
    
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§ÛŒÛŒ:\n")
    for kw1, kw2 in keyword_pairs:
        relationship = analyzer.get_semantic_relationship(kw1, kw2)
        
        print(f"{kw1} â†” {kw2}")
        print(f"  Similarity: {relationship['similarity']:.2f}")
        print(f"  Relationship: {relationship['relationship']}")
        print(f"  Confidence: {relationship['confidence']:.2f}")
        print()


async def example_complete_workflow():
    """Ù…Ø«Ø§Ù„: workflow Ú©Ø§Ù…Ù„"""
    
    analyzer = SemanticKeywordAnalyzer()
    
    if not analyzer.model_loaded:
        print("âš ï¸ Semantic model not loaded.")
        print("\nØ¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Semantic Analysis:")
        print("1. pip install sentence-transformers")
        print("2. Ù…Ø¯Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
        return
    
    main_keyword = "seo"
    
    print(f"ğŸ” ØªØ­Ù„ÛŒÙ„ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ '{main_keyword}'\n")
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ
    print("ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 1: Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ...")
    semantic_keywords = await analyzer.find_semantic_keywords(
        main_keyword=main_keyword,
        threshold=0.6,
        top_n=20,
        language='en'
    )
    
    print(f"âœ… {len(semantic_keywords)} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯\n")
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    if semantic_keywords:
        print("ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 2: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ...")
        keywords_list = [kw['keyword'] for kw in semantic_keywords]
        clusters = await analyzer.cluster_semantic_keywords(
            keywords=keywords_list,
            n_clusters=3
        )
        
        if clusters:
            print(f"âœ… {len(clusters)} Ø®ÙˆØ´Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯\n")
            for cluster_id, cluster_keywords in clusters.items():
                print(f"Ø®ÙˆØ´Ù‡ {cluster_id + 1}: {', '.join(cluster_keywords[:5])}")
    
    # Ù…Ø±Ø­Ù„Ù‡ 3: Ú¯Ø³ØªØ±Ø´ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
    print(f"\nğŸ“ Ù…Ø±Ø­Ù„Ù‡ 3: Ú¯Ø³ØªØ±Ø´ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ '{main_keyword}'...")
    expanded = await analyzer.expand_keyword_semantically(
        keyword=main_keyword,
        expansion_type='related',
        language='en'
    )
    
    print(f"âœ… {len(expanded)} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ú¯Ø³ØªØ±Ø´ ÛŒØ§ÙØªÙ‡:")
    for kw in expanded[:10]:
        print(f"  â€¢ {kw}")


if __name__ == "__main__":
    print("=" * 60)
    print("Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Semantic Keyword Analyzer")
    print("=" * 60)
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§
    # asyncio.run(example_find_semantic_keywords())
    # asyncio.run(example_lsi_keywords())
    # asyncio.run(example_cluster_keywords())
    # asyncio.run(example_expand_keyword())
    # asyncio.run(example_semantic_relationship())
    asyncio.run(example_complete_workflow())

