"""
Ù…Ø­Ø§Ø³Ø¨Ù‡ Keyword Difficulty Ù¾ÛŒØ´Ø±ÙØªÙ‡
ØªØ­Ù„ÛŒÙ„ Ø³Ø®ØªÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
"""

import logging
import httpx
import re
from typing import Dict, Any, List, Optional
from urllib.parse import urlparse
from datetime import datetime
from bs4 import BeautifulSoup
import asyncio

logger = logging.getLogger(__name__)


class KeywordDifficultyCalculator:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø­Ø§Ø³Ø¨Ù‡ Keyword Difficulty
    
    Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø®ØªÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³:
    - Domain Authority Ø±Ù‚Ø¨Ø§
    - ØªØ¹Ø¯Ø§Ø¯ Backlinks ØµÙØ­Ø§Øª Ø±ØªØ¨Ù‡â€ŒØ¯Ø§Ø±
    - Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§ÛŒ Ø±Ù‚Ø¨Ø§
    - Ø³Ù† Ø¯Ø§Ù…Ù†Ù‡
    - Ù‚Ø¯Ø±Øª Ø¨Ø±Ù†Ø¯
    """
    
    def __init__(self):
        self.client = httpx.AsyncClient(
            timeout=30.0,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        )
        
        # Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø±Ù‚Ø§Ø¨Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯)
        self.strong_brands = {
            'wikipedia.org', 'youtube.com', 'amazon.com', 'facebook.com',
            'twitter.com', 'linkedin.com', 'reddit.com', 'pinterest.com',
            'instagram.com', 'quora.com', 'medium.com', 'wordpress.com',
            'blogger.com', 'tumblr.com', 'github.com', 'stackoverflow.com'
        }
    
    async def calculate_difficulty(
        self,
        keyword: str,
        language: str = 'fa',
        use_apis: bool = True
    ) -> Dict[str, Any]:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø®ØªÛŒ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ
        
        Args:
            keyword: Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
            language: Ø²Ø¨Ø§Ù†
            use_apis: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² APIÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ (SEMrush, Ahrefs) Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯
        
        Returns:
            {
                'difficulty_score': int,  # 0-100
                'difficulty_level': str,  # 'easy', 'medium', 'hard'
                'estimated_effort': str,  # 'low', 'medium', 'high'
                'competitor_analysis': Dict,
                'factors': Dict,  # ÙØ§Ú©ØªÙˆØ±Ù‡Ø§ÛŒ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø±
                'recommendations': List[str]
            }
        """
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ
            search_results = await self._get_search_results(keyword, language)
            
            if not search_results or not search_results.get('top_domains'):
                return self._default_difficulty(keyword, "No search results found")
            
            top_domains = search_results['top_domains']
            total_results = search_results.get('total_results', 0)
            
            # ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§
            competitor_analysis = await self._analyze_competitors(
                top_domains,
                keyword,
                use_apis
            )
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§
            factors = self._calculate_factors(
                competitor_analysis,
                total_results,
                keyword
            )
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Difficulty Score
            difficulty_score = self._calculate_difficulty_score(factors)
            
            # ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­
            difficulty_level = self._get_difficulty_level(difficulty_score)
            estimated_effort = self._get_estimated_effort(difficulty_score)
            
            # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            recommendations = self._generate_recommendations(
                difficulty_score,
                factors,
                competitor_analysis
            )
            
            return {
                'difficulty_score': difficulty_score,
                'difficulty_level': difficulty_level,
                'estimated_effort': estimated_effort,
                'competitor_analysis': competitor_analysis,
                'factors': factors,
                'recommendations': recommendations,
                'keyword': keyword,
                'total_results': total_results,
                'analyzed_competitors': len(top_domains)
            }
            
        except Exception as e:
            logger.error(f"Error calculating keyword difficulty: {str(e)}")
            return self._default_difficulty(keyword, str(e))
    
    async def _get_search_results(
        self,
        keyword: str,
        language: str = 'fa'
    ) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø§Ø² Google"""
        try:
            url = "https://www.google.com/search"
            params = {
                'q': keyword,
                'hl': language,
                'num': 10
            }
            
            response = await self.client.get(url, params=params)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†ØªØ§ÛŒØ¬
                result_stats = soup.find('div', {'id': 'result-stats'})
                total_results = 0
                if result_stats:
                    text = result_stats.get_text()
                    numbers = re.findall(r'[\d,]+', text.replace(',', ''))
                    if numbers:
                        total_results = int(numbers[0].replace(',', ''))
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¯Ø§Ø± (10 Ù†ØªÛŒØ¬Ù‡ Ø§ÙˆÙ„)
                top_domains = []
                search_results = soup.find_all('div', class_='g')[:10]
                
                for result in search_results:
                    link = result.find('a', href=True)
                    if link:
                        href = link['href']
                        if 'http' in href:
                            try:
                                domain = urlparse(href).netloc
                                if domain and domain not in top_domains:
                                    top_domains.append(domain)
                            except:
                                continue
                
                return {
                    'total_results': total_results,
                    'top_domains': top_domains
                }
        except Exception as e:
            logger.error(f"Error getting search results: {str(e)}")
        
        return {}
    
    async def _analyze_competitors(
        self,
        domains: List[str],
        keyword: str,
        use_apis: bool
    ) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§"""
        competitor_data = []
        
        for domain in domains[:10]:  # ØªØ­Ù„ÛŒÙ„ 10 Ø±Ù‚ÛŒØ¨ Ø§ÙˆÙ„
            try:
                competitor_info = await self._analyze_single_competitor(
                    domain,
                    keyword,
                    use_apis
                )
                if competitor_info:
                    competitor_data.append(competitor_info)
            except Exception as e:
                logger.warning(f"Error analyzing competitor {domain}: {str(e)}")
                continue
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§
        if competitor_data:
            avg_domain_authority = sum(
                c.get('domain_authority', 0) for c in competitor_data
            ) / len(competitor_data)
            
            avg_backlinks = sum(
                c.get('backlinks', 0) for c in competitor_data
            ) / len(competitor_data)
            
            avg_content_quality = sum(
                c.get('content_quality_score', 0) for c in competitor_data
            ) / len(competitor_data)
            
            strong_brand_count = sum(
                1 for c in competitor_data if c.get('is_strong_brand', False)
            )
            
            avg_domain_age = sum(
                c.get('domain_age_years', 0) for c in competitor_data
            ) / len(competitor_data)
        else:
            avg_domain_authority = 50
            avg_backlinks = 1000
            avg_content_quality = 50
            strong_brand_count = 0
            avg_domain_age = 5
        
        return {
            'competitors': competitor_data,
            'average_domain_authority': round(avg_domain_authority, 2),
            'average_backlinks': round(avg_backlinks, 0),
            'average_content_quality': round(avg_content_quality, 2),
            'strong_brand_count': strong_brand_count,
            'average_domain_age': round(avg_domain_age, 2),
            'total_competitors_analyzed': len(competitor_data)
        }
    
    async def _analyze_single_competitor(
        self,
        domain: str,
        keyword: str,
        use_apis: bool
    ) -> Optional[Dict[str, Any]]:
        """ØªØ­Ù„ÛŒÙ„ ÛŒÚ© Ø±Ù‚ÛŒØ¨"""
        competitor_info = {
            'domain': domain,
            'domain_authority': 0,
            'backlinks': 0,
            'content_quality_score': 0,
            'is_strong_brand': domain.lower() in self.strong_brands,
            'domain_age_years': 0
        }
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² APIÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯
        if use_apis:
            # Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø§Ø² SEMrush Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
            try:
                from .semrush_client import SEMrushKeywordAnalyzer
                semrush = SEMrushKeywordAnalyzer()
                if semrush.enabled:
                    # Ø¯Ø±ÛŒØ§ÙØª Domain Authority Ø§Ø² SEMrush
                    # (Ø§ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ endpoint Ø®Ø§Øµ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø³Ø§Ø¯Ù‡ Ø´Ø¯Ù‡)
                    pass
            except:
                pass
            
            # Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø§Ø² Ahrefs Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
            try:
                from .ahrefs_client import AhrefsKeywordAnalyzer
                ahrefs = AhrefsKeywordAnalyzer()
                if ahrefs.enabled:
                    # Ø¯Ø±ÛŒØ§ÙØª Domain Rating Ø§Ø² Ahrefs
                    # (Ø§ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ endpoint Ø®Ø§Øµ Ø¯Ø§Ø±Ø¯)
                    pass
            except:
                pass
        
        # Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†: ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ
        competitor_info['domain_authority'] = self._estimate_domain_authority(domain)
        competitor_info['backlinks'] = self._estimate_backlinks(domain)
        competitor_info['content_quality_score'] = await self._estimate_content_quality(
            domain,
            keyword
        )
        competitor_info['domain_age_years'] = await self._estimate_domain_age(domain)
        
        return competitor_info
    
    def _estimate_domain_authority(self, domain: str) -> int:
        """ØªØ®Ù…ÛŒÙ† Domain Authority"""
        # Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ
        if domain.lower() in self.strong_brands:
            return 90
        
        # Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ .edu, .gov Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Authority Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù†Ø¯
        if domain.endswith('.edu') or domain.endswith('.gov'):
            return 85
        
        # Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ .org Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Authority Ù…ØªÙˆØ³Ø·-Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ù†Ø¯
        if domain.endswith('.org'):
            return 60
        
        # ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø·ÙˆÙ„ Ø¯Ø§Ù…Ù†Ù‡ (Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ØªØ± Ù‡Ø³ØªÙ†Ø¯)
        domain_length = len(domain.replace('.', ''))
        if domain_length < 10:
            return 70
        elif domain_length < 15:
            return 55
        else:
            return 45
    
    def _estimate_backlinks(self, domain: str) -> int:
        """ØªØ®Ù…ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Backlinks"""
        # Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ
        if domain.lower() in self.strong_brands:
            return 1000000
        
        # Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ .edu, .gov
        if domain.endswith('.edu') or domain.endswith('.gov'):
            return 500000
        
        # ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø¯Ø§Ù…Ù†Ù‡
        if domain.endswith('.org'):
            return 100000
        
        # ØªØ®Ù…ÛŒÙ† Ù¾Ø§ÛŒÙ‡
        return 10000
    
    async def _estimate_content_quality(
        self,
        domain: str,
        keyword: str
    ) -> int:
        """ØªØ®Ù…ÛŒÙ† Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§"""
        try:
            # Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒÙ…
            url = f"https://{domain}"
            response = await self.client.get(url, timeout=10.0)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ H1
                h1_count = len(soup.find_all('h1'))
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Meta Description
                meta_desc = soup.find('meta', attrs={'name': 'description'})
                has_meta_desc = meta_desc is not None
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§
                text_content = soup.get_text()
                word_count = len(text_content.split())
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²
                score = 0
                
                if h1_count > 0:
                    score += 20
                if has_meta_desc:
                    score += 20
                if word_count > 500:
                    score += 30
                elif word_count > 200:
                    score += 20
                else:
                    score += 10
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ Alt
                images = soup.find_all('img')
                images_with_alt = sum(1 for img in images if img.get('alt'))
                if images:
                    alt_ratio = images_with_alt / len(images)
                    score += int(alt_ratio * 30)
                
                return min(score, 100)
        except:
            pass
        
        # Fallback: ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø¯Ø§Ù…Ù†Ù‡
        if domain.lower() in self.strong_brands:
            return 80
        elif domain.endswith('.edu') or domain.endswith('.gov'):
            return 75
        else:
            return 50
    
    async def _estimate_domain_age(self, domain: str) -> int:
        """ØªØ®Ù…ÛŒÙ† Ø³Ù† Ø¯Ø§Ù…Ù†Ù‡ (Ø¨Ù‡ Ø³Ø§Ù„)"""
        # Ø§ÛŒÙ† ÛŒÚ© ØªØ®Ù…ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ø§Ø³Øª
        # Ø¯Ø± Ø­Ø§Ù„Øª ÙˆØ§Ù‚Ø¹ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² WHOIS API Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯
        
        # Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ù‡Ø³ØªÙ†Ø¯
        if domain.lower() in self.strong_brands:
            return 15
        
        # Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ .edu, .gov Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ù‡Ø³ØªÙ†Ø¯
        if domain.endswith('.edu') or domain.endswith('.gov'):
            return 10
        
        # ØªØ®Ù…ÛŒÙ† Ù¾Ø§ÛŒÙ‡
        return 5
    
    def _calculate_factors(
        self,
        competitor_analysis: Dict[str, Any],
        total_results: int,
        keyword: str
    ) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§ÛŒ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø±"""
        
        avg_da = competitor_analysis.get('average_domain_authority', 50)
        avg_backlinks = competitor_analysis.get('average_backlinks', 1000)
        avg_content_quality = competitor_analysis.get('average_content_quality', 50)
        strong_brand_count = competitor_analysis.get('strong_brand_count', 0)
        avg_domain_age = competitor_analysis.get('average_domain_age', 5)
        keyword_length = len(keyword.split())
        
        return {
            'domain_authority_impact': self._normalize_factor(avg_da, 0, 100),
            'backlinks_impact': self._normalize_factor(avg_backlinks, 0, 100000, reverse=True),
            'content_quality_impact': self._normalize_factor(avg_content_quality, 0, 100),
            'brand_strength_impact': min(strong_brand_count / 10, 1.0),
            'domain_age_impact': self._normalize_factor(avg_domain_age, 0, 20),
            'search_results_impact': self._normalize_factor(total_results, 0, 10000000),
            'keyword_length_impact': 1.0 - (min(keyword_length, 5) / 5) * 0.3  # Long-tail Ø¢Ø³Ø§Ù†â€ŒØªØ±
        }
    
    def _normalize_factor(
        self,
        value: float,
        min_val: float,
        max_val: float,
        reverse: bool = False
    ) -> float:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ§Ú©ØªÙˆØ± Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ 0-1"""
        if max_val == min_val:
            return 0.5
        
        normalized = (value - min_val) / (max_val - min_val)
        normalized = max(0, min(1, normalized))
        
        if reverse:
            return 1 - normalized
        return normalized
    
    def _calculate_difficulty_score(self, factors: Dict[str, Any]) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Difficulty Score"""
        
        # ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§
        weights = {
            'domain_authority_impact': 0.25,
            'backlinks_impact': 0.20,
            'content_quality_impact': 0.15,
            'brand_strength_impact': 0.15,
            'domain_age_impact': 0.10,
            'search_results_impact': 0.10,
            'keyword_length_impact': 0.05
        }
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² ÙˆØ²Ù†ÛŒ
        weighted_score = sum(
            factors.get(factor, 0) * weight
            for factor, weight in weights.items()
        )
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ 0-100
        difficulty_score = int(weighted_score * 100)
        
        return max(0, min(100, difficulty_score))
    
    def _get_difficulty_level(self, score: int) -> str:
        """ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­ Ø³Ø®ØªÛŒ"""
        if score < 30:
            return 'easy'
        elif score < 70:
            return 'medium'
        else:
            return 'hard'
    
    def _get_estimated_effort(self, score: int) -> str:
        """ØªØ®Ù…ÛŒÙ† ØªÙ„Ø§Ø´ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"""
        if score < 30:
            return 'low'
        elif score < 70:
            return 'medium'
        else:
            return 'high'
    
    def _generate_recommendations(
        self,
        difficulty_score: int,
        factors: Dict[str, Any],
        competitor_analysis: Dict[str, Any]
    ) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recommendations = []
        
        if difficulty_score >= 70:
            recommendations.append("Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø±Ù‚Ø§Ø¨Øª Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯:")
            recommendations.append("- Ø±ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Long-tail ØªÙ…Ø±Ú©Ø² Ú©Ù†ÛŒØ¯")
            recommendations.append("- Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ùˆ Ø¬Ø§Ù…Ø¹ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯")
            recommendations.append("- Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Link Building Ù‚ÙˆÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯")
            recommendations.append("- ØµØ¨Ø± Ùˆ Ù¾Ø´ØªÚ©Ø§Ø± Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ (6-12 Ù…Ø§Ù‡)")
        elif difficulty_score >= 40:
            recommendations.append("Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø±Ù‚Ø§Ø¨Øª Ù…ØªÙˆØ³Ø·ÛŒ Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯:")
            recommendations.append("- Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ùˆ Ø§Ø±Ø²Ø´Ù…Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯")
            recommendations.append("- Internal Linking Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯")
            recommendations.append("- Social Signals Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯")
            recommendations.append("- Ø§Ù†ØªØ¸Ø§Ø± Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 3-6 Ù…Ø§Ù‡")
        else:
            recommendations.append("Ø§ÛŒÙ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ ÙØ±ØµØª Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯:")
            recommendations.append("- Ù…Ø­ØªÙˆØ§ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ùˆ Ù…Ø±ØªØ¨Ø· ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯")
            recommendations.append("- Technical SEO Ø±Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù†ÛŒØ¯")
            recommendations.append("- Local SEO Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯")
            recommendations.append("- Ø§Ù†ØªØ¸Ø§Ø± Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 1-3 Ù…Ø§Ù‡")
        
        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§Ú©ØªÙˆØ±Ù‡Ø§
        if factors.get('brand_strength_impact', 0) > 0.5:
            recommendations.append("âš ï¸ ØªÙˆØ¬Ù‡: Ø±Ù‚Ø¨Ø§ÛŒ Ù‚ÙˆÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø¯Ù‡Ø§ÛŒ Ù…Ø¹Ø±ÙˆÙ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ Ø­Ø¶ÙˆØ± Ø¯Ø§Ø±Ù†Ø¯")
        
        if factors.get('domain_authority_impact', 0) > 0.7:
            recommendations.append("ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø±ÙˆÛŒ Domain Authority Ø®ÙˆØ¯ Ú©Ø§Ø± Ú©Ù†ÛŒØ¯")
        
        if factors.get('backlinks_impact', 0) > 0.7:
            recommendations.append("ğŸ”— Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Link Building Ø±Ø§ ØªÙ‚ÙˆÛŒØª Ú©Ù†ÛŒØ¯")
        
        return recommendations
    
    def _default_difficulty(
        self,
        keyword: str,
        error_message: str
    ) -> Dict[str, Any]:
        """Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Difficulty Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        return {
            'difficulty_score': 50,
            'difficulty_level': 'medium',
            'estimated_effort': 'medium',
            'competitor_analysis': {},
            'factors': {},
            'recommendations': [
                f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡: {error_message}",
                "Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² APIÙ‡Ø§ÛŒ Ø®Ø§Ø±Ø¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
            ],
            'keyword': keyword,
            'total_results': 0,
            'analyzed_competitors': 0,
            'error': error_message
        }
    
    async def close(self):
        """Ø¨Ø³ØªÙ† client"""
        await self.client.aclose()

